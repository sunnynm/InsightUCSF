{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Description</th>\n",
       "      <th>Details</th>\n",
       "      <th>ShortDetails</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Type</th>\n",
       "      <th>Identifiers</th>\n",
       "      <th>Db</th>\n",
       "      <th>EntrezUID</th>\n",
       "      <th>Properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>011620-185708</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Evaluating risk prediction models for adults w...</td>\n",
       "      <td>/pubmed/31940350</td>\n",
       "      <td>BACKGROUND: The ability to predict risk allows...</td>\n",
       "      <td>Di Tanna GL, Wirtz H, Burrows KL, Globe G.</td>\n",
       "      <td>PloS one. doi: 10.1371/journal.pone.0224135. J...</td>\n",
       "      <td>PloS one. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31940350</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31940350</td>\n",
       "      <td>create date: 2020/01/15 | first author: Di Tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>011620-185710</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Automated Cardiovascular Pathology Assessment ...</td>\n",
       "      <td>/pubmed/31939003</td>\n",
       "      <td>Cardiac magnetic resonance imaging provides hi...</td>\n",
       "      <td>Lindsey T, Lee JJ.</td>\n",
       "      <td>Journal of digital imaging. doi: 10.1007/s1027...</td>\n",
       "      <td>Journal of digital imaging. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31939003</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31939003</td>\n",
       "      <td>create date: 2020/01/14 | first author: Lindsey T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>011620-185718</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Physiological Assessment of Coronary Lesions i...</td>\n",
       "      <td>/pubmed/31938934</td>\n",
       "      <td>PURPOSE OF REVIEW: Physiological assessment of...</td>\n",
       "      <td>Chowdhury M, Osborn EA.</td>\n",
       "      <td>Current treatment options in cardiovascular me...</td>\n",
       "      <td>Current treatment options in cardiovascular me...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31938934</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31938934</td>\n",
       "      <td>create date: 2020/01/15 | first author: Chowdh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>011620-185722</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Of Machines and Men: Intelligent Diagnosis and...</td>\n",
       "      <td>/pubmed/31938923</td>\n",
       "      <td>Artificial Intelligence (AI), although well es...</td>\n",
       "      <td>Cockcroft J, Avolio A.</td>\n",
       "      <td>Current hypertension reports. doi: 10.1007/s11...</td>\n",
       "      <td>Current hypertension reports. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31938923</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31938923</td>\n",
       "      <td>create date: 2020/01/14 | first author: Cockcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>011620-185724</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Cytosine and adenine base editing of the brain...</td>\n",
       "      <td>/pubmed/31937940</td>\n",
       "      <td>The success of base editors for the study and ...</td>\n",
       "      <td>Levy JM, Yeh WH, Pendse N, Davis JR, Hennessey...</td>\n",
       "      <td>Nature biomedical engineering. doi: 10.1038/s4...</td>\n",
       "      <td>Nature biomedical engineering. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31937940</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31937940</td>\n",
       "      <td>create date: 2020/01/14 | first author: Levy JM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>011620-194624</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Lung Innate Lymphoid Cell Composition Is Alter...</td>\n",
       "      <td>/pubmed/31394048</td>\n",
       "      <td>Comment in\\n    Am J Respir Crit Care Med. 202...</td>\n",
       "      <td>Monticelli LA, Diamond JM, Saenz SA, Tait Wojn...</td>\n",
       "      <td>American journal of respiratory and critical c...</td>\n",
       "      <td>American journal of respiratory and critical c...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31394048</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31394048</td>\n",
       "      <td>create date: 2020/01/01 | first author: Montic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>011620-195203</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Curcumin: a therapeutic strategy in cancers by...</td>\n",
       "      <td>/pubmed/31331376</td>\n",
       "      <td>Numerous studies have presented that curcumin ...</td>\n",
       "      <td>Vallée A, Lecarpentier Y, Vallée JN.</td>\n",
       "      <td>Journal of experimental &amp;amp; clinical cancer ...</td>\n",
       "      <td>Journal of experimental &amp;amp; clinical cancer ...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31331376</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331376</td>\n",
       "      <td>create date: 2019/07/22 | first author: Vallée A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>011620-195211</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Extra Virgin Olive Oil Contains a Phenolic Inh...</td>\n",
       "      <td>/pubmed/31331073</td>\n",
       "      <td>The lysine-specific histone demethylase 1A (LS...</td>\n",
       "      <td>Cuyàs E, Gumuzio J, Lozano-Sánchez J, Carreras...</td>\n",
       "      <td>Nutrients. pii: E1656. doi: 10.3390/nu11071656...</td>\n",
       "      <td>Nutrients. 2019</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31331073</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331073</td>\n",
       "      <td>create date: 2019/07/19 | first author: Cuyàs E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>977</td>\n",
       "      <td>011620-195219</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Effect of Vasicinone against Paraquat-Induced ...</td>\n",
       "      <td>/pubmed/31331066</td>\n",
       "      <td>Vasicinone is a quinazoline alkaloid isolated ...</td>\n",
       "      <td>Ju DT, Sivalingam K, Kuo WW, Ho TJ, Chang RL, ...</td>\n",
       "      <td>Nutrients. pii: E1655. doi: 10.3390/nu11071655...</td>\n",
       "      <td>Nutrients. 2019</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31331066</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331066</td>\n",
       "      <td>create date: 2019/07/19 | first author: Ju DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>011620-195259</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Practical guide for the use of PCSK9 inhibitor...</td>\n",
       "      <td>/pubmed/31324407</td>\n",
       "      <td>Reducing low-density lipoprotein cholesterol (...</td>\n",
       "      <td>Fontes-Carvalho R, Marques Silva P, Rodrigues ...</td>\n",
       "      <td>Revista portuguesa de cardiologia : orgao ofic...</td>\n",
       "      <td>Revista portuguesa de cardiologia : orgao ofic...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31324407</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31324407</td>\n",
       "      <td>create date: 2019/06/01 | first author: Fontes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DateTime                                            Keyword  \\\n",
       "0    011620-185708  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "1    011620-185710  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "2    011620-185718  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "3    011620-185722  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "4    011620-185724  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "..             ...                                                ...   \n",
       "876  011620-194624  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "974  011620-195203  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "976  011620-195211  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "977  011620-195219  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "991  011620-195259  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "\n",
       "                                                 Title               URL  \\\n",
       "0    Evaluating risk prediction models for adults w...  /pubmed/31940350   \n",
       "1    Automated Cardiovascular Pathology Assessment ...  /pubmed/31939003   \n",
       "2    Physiological Assessment of Coronary Lesions i...  /pubmed/31938934   \n",
       "3    Of Machines and Men: Intelligent Diagnosis and...  /pubmed/31938923   \n",
       "4    Cytosine and adenine base editing of the brain...  /pubmed/31937940   \n",
       "..                                                 ...               ...   \n",
       "876  Lung Innate Lymphoid Cell Composition Is Alter...  /pubmed/31394048   \n",
       "974  Curcumin: a therapeutic strategy in cancers by...  /pubmed/31331376   \n",
       "976  Extra Virgin Olive Oil Contains a Phenolic Inh...  /pubmed/31331073   \n",
       "977  Effect of Vasicinone against Paraquat-Induced ...  /pubmed/31331066   \n",
       "991  Practical guide for the use of PCSK9 inhibitor...  /pubmed/31324407   \n",
       "\n",
       "                                              Abstract  \\\n",
       "0    BACKGROUND: The ability to predict risk allows...   \n",
       "1    Cardiac magnetic resonance imaging provides hi...   \n",
       "2    PURPOSE OF REVIEW: Physiological assessment of...   \n",
       "3    Artificial Intelligence (AI), although well es...   \n",
       "4    The success of base editors for the study and ...   \n",
       "..                                                 ...   \n",
       "876  Comment in\\n    Am J Respir Crit Care Med. 202...   \n",
       "974  Numerous studies have presented that curcumin ...   \n",
       "976  The lysine-specific histone demethylase 1A (LS...   \n",
       "977  Vasicinone is a quinazoline alkaloid isolated ...   \n",
       "991  Reducing low-density lipoprotein cholesterol (...   \n",
       "\n",
       "                                           Description  \\\n",
       "0           Di Tanna GL, Wirtz H, Burrows KL, Globe G.   \n",
       "1                                   Lindsey T, Lee JJ.   \n",
       "2                              Chowdhury M, Osborn EA.   \n",
       "3                               Cockcroft J, Avolio A.   \n",
       "4    Levy JM, Yeh WH, Pendse N, Davis JR, Hennessey...   \n",
       "..                                                 ...   \n",
       "876  Monticelli LA, Diamond JM, Saenz SA, Tait Wojn...   \n",
       "974               Vallée A, Lecarpentier Y, Vallée JN.   \n",
       "976  Cuyàs E, Gumuzio J, Lozano-Sánchez J, Carreras...   \n",
       "977  Ju DT, Sivalingam K, Kuo WW, Ho TJ, Chang RL, ...   \n",
       "991  Fontes-Carvalho R, Marques Silva P, Rodrigues ...   \n",
       "\n",
       "                                               Details  \\\n",
       "0    PloS one. doi: 10.1371/journal.pone.0224135. J...   \n",
       "1    Journal of digital imaging. doi: 10.1007/s1027...   \n",
       "2    Current treatment options in cardiovascular me...   \n",
       "3    Current hypertension reports. doi: 10.1007/s11...   \n",
       "4    Nature biomedical engineering. doi: 10.1038/s4...   \n",
       "..                                                 ...   \n",
       "876  American journal of respiratory and critical c...   \n",
       "974  Journal of experimental &amp; clinical cancer ...   \n",
       "976  Nutrients. pii: E1656. doi: 10.3390/nu11071656...   \n",
       "977  Nutrients. pii: E1655. doi: 10.3390/nu11071655...   \n",
       "991  Revista portuguesa de cardiologia : orgao ofic...   \n",
       "\n",
       "                                          ShortDetails Resource  \\\n",
       "0                                       PloS one. 2020   PubMed   \n",
       "1                     Journal of digital imaging. 2020   PubMed   \n",
       "2    Current treatment options in cardiovascular me...   PubMed   \n",
       "3                   Current hypertension reports. 2020   PubMed   \n",
       "4                  Nature biomedical engineering. 2020   PubMed   \n",
       "..                                                 ...      ...   \n",
       "876  American journal of respiratory and critical c...   PubMed   \n",
       "974  Journal of experimental &amp; clinical cancer ...   PubMed   \n",
       "976                                    Nutrients. 2019   PubMed   \n",
       "977                                    Nutrients. 2019   PubMed   \n",
       "991  Revista portuguesa de cardiologia : orgao ofic...   PubMed   \n",
       "\n",
       "                        Type    Identifiers      Db  EntrezUID  \\\n",
       "0            Journal Article  PMID:31940350  pubmed   31940350   \n",
       "1            Journal Article  PMID:31939003  pubmed   31939003   \n",
       "2    Journal Article, Review  PMID:31938934  pubmed   31938934   \n",
       "3    Journal Article, Review  PMID:31938923  pubmed   31938923   \n",
       "4            Journal Article  PMID:31937940  pubmed   31937940   \n",
       "..                       ...            ...     ...        ...   \n",
       "876          Journal Article  PMID:31394048  pubmed   31394048   \n",
       "974  Journal Article, Review  PMID:31331376  pubmed   31331376   \n",
       "976          Journal Article  PMID:31331073  pubmed   31331073   \n",
       "977          Journal Article  PMID:31331066  pubmed   31331066   \n",
       "991  Journal Article, Review  PMID:31324407  pubmed   31324407   \n",
       "\n",
       "                                            Properties  \n",
       "0    create date: 2020/01/15 | first author: Di Tan...  \n",
       "1    create date: 2020/01/14 | first author: Lindsey T  \n",
       "2    create date: 2020/01/15 | first author: Chowdh...  \n",
       "3    create date: 2020/01/14 | first author: Cockcr...  \n",
       "4      create date: 2020/01/14 | first author: Levy JM  \n",
       "..                                                 ...  \n",
       "876  create date: 2020/01/01 | first author: Montic...  \n",
       "974   create date: 2019/07/22 | first author: Vallée A  \n",
       "976    create date: 2019/07/19 | first author: Cuyàs E  \n",
       "977      create date: 2019/07/19 | first author: Ju DT  \n",
       "991  create date: 2019/06/01 | first author: Fontes...  \n",
       "\n",
       "[88 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#creating a pandas dataframe out of the csv file\n",
    "traindf = pd.read_csv('../Data/08.Pubmed_PDFs_011620.csv')\n",
    "testdf = pd.read_csv('../Data/04.Pubmed_PDFs_011320.csv')\n",
    "\n",
    "out = [x[:13] for x in testdf[\"Identifiers\"]]\n",
    "#print(out)\n",
    "\n",
    "subdf = traindf[~traindf[\"Identifiers\"].isin(out)]\n",
    "print(subdf.shape)\n",
    "subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words=text.ENGLISH_STOP_WORDS)\n",
    "documentlist = subdf['Abstract'].values\n",
    "X = vectorizer.fit_transform(documentlist)\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study',\n",
       " 'disease',\n",
       " 'heart',\n",
       " 'associated',\n",
       " 'treatment',\n",
       " 'use',\n",
       " 'cell',\n",
       " 'diseases',\n",
       " 'therapeutic',\n",
       " 'ability',\n",
       " 'type',\n",
       " 'targeted',\n",
       " 'limited',\n",
       " 'tissues',\n",
       " 'efficient',\n",
       " 'causes',\n",
       " 'increasing',\n",
       " 'genetic',\n",
       " 'introduction',\n",
       " 'mutations',\n",
       " 'multiple',\n",
       " 'application',\n",
       " '20',\n",
       " 'report',\n",
       " 'muscle',\n",
       " 'facilitate',\n",
       " 'liver',\n",
       " 'neurodegenerative',\n",
       " 'point',\n",
       " 'deliver',\n",
       " 'enable',\n",
       " 'depends',\n",
       " 'types',\n",
       " 'viruses',\n",
       " 'capacity',\n",
       " 'length',\n",
       " 'adenine',\n",
       " '59',\n",
       " 'cortical',\n",
       " 'skeletal',\n",
       " 'mutation',\n",
       " 'slowing',\n",
       " 'neurodegeneration',\n",
       " 'vectors',\n",
       " 'tissue',\n",
       " 'success',\n",
       " 'adeno',\n",
       " 'aav',\n",
       " 'packaging',\n",
       " 'precludes',\n",
       " 'split',\n",
       " 'cytosine',\n",
       " 'reconstituted',\n",
       " 'trans',\n",
       " 'splicing',\n",
       " 'inteins',\n",
       " 'therapeutically',\n",
       " 'efficiencies',\n",
       " 'dosages',\n",
       " 'unsorted',\n",
       " 'retina',\n",
       " 'corrects',\n",
       " 'niemann',\n",
       " 'pick',\n",
       " 'ataxia',\n",
       " 'lifespan',\n",
       " 'relevant',\n",
       " 'vivo',\n",
       " 'brain',\n",
       " 'mouse',\n",
       " '38',\n",
       " 'dual',\n",
       " 'optimized',\n",
       " 'editing',\n",
       " 'delivery',\n",
       " 'editors',\n",
       " 'aavs',\n",
       " 'base']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc =  4\n",
    "wordlist = X[doc,:].nonzero()[1]\n",
    "vallist = [X[doc, x] for x in wordlist]\n",
    "topwords = sorted(range(len(vallist)), key=lambda i: vallist[i])[-200:]\n",
    "[words[i] for i in wordlist[topwords]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04034532205181334,\n",
       " 0.0459783742357598,\n",
       " 0.0466999883519598,\n",
       " 0.049839998484588886,\n",
       " 0.05069779596505863,\n",
       " 0.056661056409636486,\n",
       " 0.05782689838935194,\n",
       " 0.06173287179469072,\n",
       " 0.06645229352398956,\n",
       " 0.07241555396856741,\n",
       " 0.07241555396856741,\n",
       " 0.0748102863331974,\n",
       " 0.07748736935362165,\n",
       " 0.07748736935362165,\n",
       " 0.08052239576380518,\n",
       " 0.08052239576380518,\n",
       " 0.08052239576380518,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.09324186691255257,\n",
       " 0.09324186691255257,\n",
       " 0.09324186691255257,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.10452283782704917,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.12261019103056649,\n",
       " 0.1266648253819354,\n",
       " 0.13633626735941884,\n",
       " 0.1422685147275347,\n",
       " 0.14928487415360892,\n",
       " 0.18454688719617648,\n",
       " 0.18454688719617648,\n",
       " 0.18454688719617648,\n",
       " 0.20940073914829785,\n",
       " 0.22874110990000346,\n",
       " 0.22874110990000346,\n",
       " 0.2844192457693743]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vallist[i] for i in topwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term data demonstrating improved outcomes', 'determine lesion functional significance', 'beyond fractional flow reserve', 'ffrct ), invasive angiography', 'guided percutaneous coronary intervention', 'evaluating coronary stenosis physiology', 'coronary physiological assessment remains', 'invasive coronary ct', 'coronary physiological assessment', 'coronary artery disease', 'acute coronary syndromes', 'technical aspects involved', 'rest without hyperemia', 'residual ischemia post', 'optical coherence tomography', 'interventional cardiology toolbox', 'improve patient care', 'hyperemic pressure ratios', 'exciting technological future', 'enable detailed pre', 'artificial intelligence algorithms', 'alternative ffr approaches', 'assess coronary physiology', 'refine clinical practice', 'ffr ), non', 'physiological assessment', 'coronary physiology', 'remains underutilized', 'ffroct ),', 'ffrangio ),', 'current practice', 'clinical scenarios', 'well established', 'serial lesions', 'robust tools', 'related arteries', 'recent findings', 'left main', 'latest developments', 'indispensable tool', 'including non', 'essential component', 'especially helpful', 'despite long', 'catheterization laboratory', 'also emerging', 'additional advances', 'stable cad', 'multivessel cad', 'review outlines', 'physiology', 'intervention', 'non', 'cad', 'review', 'virtual', 'today', 'realized', 'purpose', 'procedure', 'pci', 'nhpr', 'infarct', 'indications', 'however', 'focusing', 'field', 'benefits', 'addition', 'abound']\n",
      "[(25.0, 'term data demonstrating improved outcomes'), (16.0, 'determine lesion functional significance'), (16.0, 'beyond fractional flow reserve'), (14.25, 'ffrct ), invasive angiography'), (13.722222222222221, 'guided percutaneous coronary intervention'), (13.722222222222221, 'evaluating coronary stenosis physiology'), (12.222222222222221, 'coronary physiological assessment remains'), (9.722222222222221, 'invasive coronary ct'), (9.222222222222221, 'coronary physiological assessment'), (9.222222222222221, 'coronary artery disease'), (9.222222222222221, 'acute coronary syndromes'), (9.0, 'technical aspects involved'), (9.0, 'rest without hyperemia'), (9.0, 'residual ischemia post'), (9.0, 'optical coherence tomography'), (9.0, 'interventional cardiology toolbox'), (9.0, 'improve patient care'), (9.0, 'hyperemic pressure ratios'), (9.0, 'exciting technological future'), (9.0, 'enable detailed pre'), (9.0, 'artificial intelligence algorithms'), (9.0, 'alternative ffr approaches'), (8.722222222222221, 'assess coronary physiology'), (8.0, 'refine clinical practice'), (7.75, 'ffr ), non'), (6.0, 'physiological assessment'), (5.722222222222222, 'coronary physiology'), (5.0, 'remains underutilized'), (4.75, 'ffroct ),'), (4.75, 'ffrangio ),'), (4.5, 'current practice'), (4.5, 'clinical scenarios'), (4.0, 'well established'), (4.0, 'serial lesions'), (4.0, 'robust tools'), (4.0, 'related arteries'), (4.0, 'recent findings'), (4.0, 'left main'), (4.0, 'latest developments'), (4.0, 'indispensable tool'), (4.0, 'including non'), (4.0, 'essential component'), (4.0, 'especially helpful'), (4.0, 'despite long'), (4.0, 'catheterization laboratory'), (4.0, 'also emerging'), (4.0, 'additional advances'), (3.666666666666667, 'stable cad'), (3.666666666666667, 'multivessel cad'), (3.5, 'review outlines'), (2.5, 'physiology'), (2.5, 'intervention'), (2.0, 'non'), (1.6666666666666667, 'cad'), (1.5, 'review'), (1.0, 'virtual'), (1.0, 'today'), (1.0, 'realized'), (1.0, 'purpose'), (1.0, 'procedure'), (1.0, 'pci'), (1.0, 'nhpr'), (1.0, 'infarct'), (1.0, 'indications'), (1.0, 'however'), (1.0, 'focusing'), (1.0, 'field'), (1.0, 'benefits'), (1.0, 'addition'), (1.0, 'abound')]\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake #https://pypi.org/project/rake-nltk/\n",
    "from nltk.corpus import stopwords \n",
    "r = Rake(stopwords = stopwords.words(\"english\"), max_length = 5) # Uses stopwords for english from NLTK, and all puntuation characters.Please note that \"hello\" is not included in the list of stopwords.\n",
    "\n",
    "a=r.extract_keywords_from_text(subdf['Abstract'][2])\n",
    "b=r.get_ranked_phrases()\n",
    "c=r.get_ranked_phrases_with_scores()\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.0, 'determine lesion functional significance')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../Data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'recent findings' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-b14178f30b47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cardiology'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recent findings'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.most_similar(positive=['cardiology'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \"\"\"\n\u001b[1;32m--> 955\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, entities)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'recent findings' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model.similarity('cardiology', 'recent findings')\n",
    "#model.most_similar(positive=['cardiology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'svm' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-c5246b1e4428>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'svm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'svm' not in vocabulary\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "60",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-d3d121f42d2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mewrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Document'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RakeVal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SimVal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_keywords_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ranked_phrases_with_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 60"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake #https://pypi.org/project/rake-nltk/\n",
    "from nltk.corpus import stopwords \n",
    "import time\n",
    "start_time = time.time()\n",
    "r = Rake(stopwords = stopwords.words(\"english\"), max_length = 5) # Uses stopwords for english from NLTK, and all puntuation characters.Please note that \"hello\" is not included in the list of stopwords.\n",
    "counter = 0\n",
    "import csv\n",
    "with open('../Data/Cardiolgydistance.csv', mode='w', encoding='UTF-8') as file:\n",
    "    ewrite = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    ewrite.writerow(['Document', 'Phrase', 'RakeVal', 'SimVal'])\n",
    "    for i in range(len(subdf['Abstract'])):\n",
    "        a = r.extract_keywords_from_text(subdf['Abstract'][i])\n",
    "        c=r.get_ranked_phrases_with_scores()\n",
    "        for j in c:\n",
    "            cosinevallist = []\n",
    "            for k in j[1].split():\n",
    "                try:\n",
    "                    cval = model.similarity('cardiology', k)\n",
    "                except:\n",
    "                    cval = 0\n",
    "                if cval != 0:\n",
    "                    cosinevallist.append(cval)\n",
    "            if len(cosinevallist) > 0:\n",
    "                mcval = sum(cosinevallist) / len(cosinevallist)\n",
    "            else:\n",
    "                mcval = 0\n",
    "            #print([counter, j[1], j[0], mcval])\n",
    "            ewrite.writerow([counter, j[1], j[0], mcval])\n",
    "    if (counter % 5 == 0):\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(counter)\n",
    "    counter+=1\n",
    "print(\"CSV done\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'approach evaluated anonymized cardiac images', 23.666666666666668, 0.17590658068656922]\n",
      "[1, 'advanced machine learning methods', 16.0, 0.05202275887131691]\n",
      "[1, 'reproducible cardiac pathological assessment', 15.666666666666666, 0.253646831959486]\n",
      "[1, 'fully automatic processing pipeline', 15.666666666666666, 0.07228710362687707]\n",
      "[1, 'cardiac cine sequencing provides', 15.666666666666666, 0.24283761950209737]\n",
      "[1, 'independent test set using', 15.5, 0.015956244431436062]\n",
      "[1, 'initial processing element consists', 15.166666666666666, 0.03378185909241438]\n",
      "[1, '20 patients per group', 14.5, 0.17405342496931553]\n",
      "[1, 'ary pathology classification accuracy', 14.333333333333334, 0.14713991759344935]\n",
      "[1, 'final processing element', 10.166666666666666, 0.023160612831513088]\n",
      "[1, 'cardiac pathology classifier', 10.0, 0.4012519071499507]\n",
      "[1, 'quantify cardiac measures', 9.666666666666666, 0.21810053630421558]\n",
      "[1, 'manual cardiac evaluation', 9.666666666666666, 0.26817435150345165]\n",
      "[1, 'training data set', 9.5, 0.07900424053271611]\n",
      "[1, '1 healthy group', 9.5, 0.05025427540143331]\n",
      "[1, '4 pathology groups', 9.333333333333334, 0.1706454207499822]\n",
      "[1, 'rv ), respectively', 9.0, 0.06496892496943474]\n",
      "[1, 'performance results demonstrate', 9.0, 0.04285929352045059]\n",
      "[1, 'enabling improved extraction', 9.0, 0.055905758713682495]\n",
      "[1, 'cardiovascular disease staging', 8.5, 0.25692620997627574]\n",
      "[1, 'lv ), myocardium', 8.0, 0.16202591359615326]\n",
      "[1, 'combining semantic segmentation', 8.0, 0.05596125001708666]\n",
      "[1, 'disease classification', 5.5, 0.09134924225509167]\n",
      "[1, '100 patients', 5.0, 0.4592966139316559]\n",
      "[1, 'wise segmentation', 4.0, 0.06757503096014261]\n",
      "[1, 'ventricular cavities', 4.0, 0.19728557020425797]\n",
      "[1, 'university hospital', 4.0, 0.32684318721294403]\n",
      "[1, 'structure segmentation', 4.0, 0.08185387216508389]\n",
      "[1, 'right ventricle', 4.0, 0.08423669962212443]\n",
      "[1, 'observer bias', 4.0, 0.04053699877113104]\n",
      "[1, 'morphological features', 4.0, 0.1226752009242773]\n",
      "[1, 'left ventricle', 4.0, 0.1010191198438406]\n",
      "[1, 'important functional', 4.0, 0.11301657184958458]\n",
      "[1, 'ejection fraction', 4.0, -0.013899685814976692]\n",
      "[1, 'deliver accurate', 4.0, 0.03067811205983162]\n",
      "[1, 'trained model', 3.5, 0.08922233246266842]\n",
      "[1, 'segmentation', 2.0, 0.13467922806739807]\n",
      "[1, 'myocardium', 2.0, 0.27229008078575134]\n",
      "[1, 'model', 1.5, 0.05463607236742973]\n",
      "[1, 'voxel', 1.0, 0.22100672125816345]\n",
      "[1, 'utilized', 1.0, 0.03543274104595184]\n",
      "[1, 'recorded', 1.0, 0.01999819651246071]\n",
      "[1, 'presented', 1.0, 0.10993251949548721]\n",
      "[1, 'potential', 1.0, 0.06813585013151169]\n",
      "[1, 'method', 1.0, 0.016362402588129044]\n",
      "[1, 'expense', 1.0, 0.08347275108098984]\n",
      "[1, 'examined', 1.0, 0.1701224148273468]\n",
      "[1, 'efficient', 1.0, 0.10318800061941147]\n",
      "[1, 'dijon', 1.0, 0.010735955089330673]\n",
      "[1, 'curtails', 1.0, 0.028310272842645645]\n",
      "[1, 'basis', 1.0, -0.04432522505521774]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-2abf670bc13a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcval\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mcosinevallist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmcval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosinevallist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosinevallist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmcval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "from statistics import mean\n",
    "a = r.extract_keywords_from_text(subdf['Abstract'][i])\n",
    "c=r.get_ranked_phrases_with_scores()\n",
    "\n",
    "    print([1, j[1], j[0], mcval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'evaluated', 'anonymized', 'cardiac', 'images']\n",
      "['advanced', 'machine', 'learning', 'methods']\n",
      "['reproducible', 'cardiac', 'pathological', 'assessment']\n",
      "['fully', 'automatic', 'processing', 'pipeline']\n",
      "['cardiac', 'cine', 'sequencing', 'provides']\n",
      "['independent', 'test', 'set', 'using']\n",
      "['initial', 'processing', 'element', 'consists']\n",
      "['20', 'patients', 'per', 'group']\n",
      "['ary', 'pathology', 'classification', 'accuracy']\n",
      "['final', 'processing', 'element']\n",
      "['cardiac', 'pathology', 'classifier']\n",
      "['quantify', 'cardiac', 'measures']\n",
      "['manual', 'cardiac', 'evaluation']\n",
      "['training', 'data', 'set']\n",
      "['1', 'healthy', 'group']\n",
      "['4', 'pathology', 'groups']\n",
      "['rv', '),', 'respectively']\n",
      "['performance', 'results', 'demonstrate']\n",
      "['enabling', 'improved', 'extraction']\n",
      "['cardiovascular', 'disease', 'staging']\n",
      "['lv', '),', 'myocardium']\n",
      "['combining', 'semantic', 'segmentation']\n",
      "['disease', 'classification']\n",
      "['100', 'patients']\n",
      "['wise', 'segmentation']\n",
      "['ventricular', 'cavities']\n",
      "['university', 'hospital']\n",
      "['structure', 'segmentation']\n",
      "['right', 'ventricle']\n",
      "['observer', 'bias']\n",
      "['morphological', 'features']\n",
      "['left', 'ventricle']\n",
      "['important', 'functional']\n",
      "['ejection', 'fraction']\n",
      "['deliver', 'accurate']\n",
      "['trained', 'model']\n",
      "['segmentation']\n",
      "['myocardium']\n",
      "['model']\n",
      "['voxel']\n",
      "['utilized']\n",
      "['recorded']\n",
      "['presented']\n",
      "['potential']\n",
      "['method']\n",
      "['expense']\n",
      "['examined']\n",
      "['efficient']\n",
      "['dijon']\n",
      "['curtails']\n",
      "['basis']\n",
      "['940']\n",
      "['90']\n",
      "['886']\n",
      "['849']\n",
      "['5']\n",
      "['0']\n"
     ]
    }
   ],
   "source": [
    "for i in c:\n",
    "    \n",
    "    print(i[1].split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
