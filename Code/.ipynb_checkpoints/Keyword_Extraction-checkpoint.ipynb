{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Description</th>\n",
       "      <th>Details</th>\n",
       "      <th>ShortDetails</th>\n",
       "      <th>Resource</th>\n",
       "      <th>Type</th>\n",
       "      <th>Identifiers</th>\n",
       "      <th>Db</th>\n",
       "      <th>EntrezUID</th>\n",
       "      <th>Properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>011620-185708</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Evaluating risk prediction models for adults w...</td>\n",
       "      <td>/pubmed/31940350</td>\n",
       "      <td>BACKGROUND: The ability to predict risk allows...</td>\n",
       "      <td>Di Tanna GL, Wirtz H, Burrows KL, Globe G.</td>\n",
       "      <td>PloS one. doi: 10.1371/journal.pone.0224135. J...</td>\n",
       "      <td>PloS one. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31940350</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31940350</td>\n",
       "      <td>create date: 2020/01/15 | first author: Di Tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>011620-185710</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Automated Cardiovascular Pathology Assessment ...</td>\n",
       "      <td>/pubmed/31939003</td>\n",
       "      <td>Cardiac magnetic resonance imaging provides hi...</td>\n",
       "      <td>Lindsey T, Lee JJ.</td>\n",
       "      <td>Journal of digital imaging. doi: 10.1007/s1027...</td>\n",
       "      <td>Journal of digital imaging. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31939003</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31939003</td>\n",
       "      <td>create date: 2020/01/14 | first author: Lindsey T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>011620-185718</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Physiological Assessment of Coronary Lesions i...</td>\n",
       "      <td>/pubmed/31938934</td>\n",
       "      <td>PURPOSE OF REVIEW: Physiological assessment of...</td>\n",
       "      <td>Chowdhury M, Osborn EA.</td>\n",
       "      <td>Current treatment options in cardiovascular me...</td>\n",
       "      <td>Current treatment options in cardiovascular me...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31938934</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31938934</td>\n",
       "      <td>create date: 2020/01/15 | first author: Chowdh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>011620-185722</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Of Machines and Men: Intelligent Diagnosis and...</td>\n",
       "      <td>/pubmed/31938923</td>\n",
       "      <td>Artificial Intelligence (AI), although well es...</td>\n",
       "      <td>Cockcroft J, Avolio A.</td>\n",
       "      <td>Current hypertension reports. doi: 10.1007/s11...</td>\n",
       "      <td>Current hypertension reports. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31938923</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31938923</td>\n",
       "      <td>create date: 2020/01/14 | first author: Cockcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>011620-185724</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Cytosine and adenine base editing of the brain...</td>\n",
       "      <td>/pubmed/31937940</td>\n",
       "      <td>The success of base editors for the study and ...</td>\n",
       "      <td>Levy JM, Yeh WH, Pendse N, Davis JR, Hennessey...</td>\n",
       "      <td>Nature biomedical engineering. doi: 10.1038/s4...</td>\n",
       "      <td>Nature biomedical engineering. 2020</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31937940</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31937940</td>\n",
       "      <td>create date: 2020/01/14 | first author: Levy JM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>011620-194624</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Lung Innate Lymphoid Cell Composition Is Alter...</td>\n",
       "      <td>/pubmed/31394048</td>\n",
       "      <td>Comment in\\n    Am J Respir Crit Care Med. 202...</td>\n",
       "      <td>Monticelli LA, Diamond JM, Saenz SA, Tait Wojn...</td>\n",
       "      <td>American journal of respiratory and critical c...</td>\n",
       "      <td>American journal of respiratory and critical c...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31394048</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31394048</td>\n",
       "      <td>create date: 2020/01/01 | first author: Montic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>011620-195203</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Curcumin: a therapeutic strategy in cancers by...</td>\n",
       "      <td>/pubmed/31331376</td>\n",
       "      <td>Numerous studies have presented that curcumin ...</td>\n",
       "      <td>Vallée A, Lecarpentier Y, Vallée JN.</td>\n",
       "      <td>Journal of experimental &amp;amp; clinical cancer ...</td>\n",
       "      <td>Journal of experimental &amp;amp; clinical cancer ...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31331376</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331376</td>\n",
       "      <td>create date: 2019/07/22 | first author: Vallée A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>011620-195211</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Extra Virgin Olive Oil Contains a Phenolic Inh...</td>\n",
       "      <td>/pubmed/31331073</td>\n",
       "      <td>The lysine-specific histone demethylase 1A (LS...</td>\n",
       "      <td>Cuyàs E, Gumuzio J, Lozano-Sánchez J, Carreras...</td>\n",
       "      <td>Nutrients. pii: E1656. doi: 10.3390/nu11071656...</td>\n",
       "      <td>Nutrients. 2019</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31331073</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331073</td>\n",
       "      <td>create date: 2019/07/19 | first author: Cuyàs E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>977</td>\n",
       "      <td>011620-195219</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Effect of Vasicinone against Paraquat-Induced ...</td>\n",
       "      <td>/pubmed/31331066</td>\n",
       "      <td>Vasicinone is a quinazoline alkaloid isolated ...</td>\n",
       "      <td>Ju DT, Sivalingam K, Kuo WW, Ho TJ, Chang RL, ...</td>\n",
       "      <td>Nutrients. pii: E1655. doi: 10.3390/nu11071655...</td>\n",
       "      <td>Nutrients. 2019</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>PMID:31331066</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31331066</td>\n",
       "      <td>create date: 2019/07/19 | first author: Ju DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>011620-195259</td>\n",
       "      <td>(\"machine learning\" OR \"deep learning\" OR \"art...</td>\n",
       "      <td>Practical guide for the use of PCSK9 inhibitor...</td>\n",
       "      <td>/pubmed/31324407</td>\n",
       "      <td>Reducing low-density lipoprotein cholesterol (...</td>\n",
       "      <td>Fontes-Carvalho R, Marques Silva P, Rodrigues ...</td>\n",
       "      <td>Revista portuguesa de cardiologia : orgao ofic...</td>\n",
       "      <td>Revista portuguesa de cardiologia : orgao ofic...</td>\n",
       "      <td>PubMed</td>\n",
       "      <td>Journal Article, Review</td>\n",
       "      <td>PMID:31324407</td>\n",
       "      <td>pubmed</td>\n",
       "      <td>31324407</td>\n",
       "      <td>create date: 2019/06/01 | first author: Fontes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DateTime                                            Keyword  \\\n",
       "0    011620-185708  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "1    011620-185710  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "2    011620-185718  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "3    011620-185722  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "4    011620-185724  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "..             ...                                                ...   \n",
       "876  011620-194624  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "974  011620-195203  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "976  011620-195211  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "977  011620-195219  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "991  011620-195259  (\"machine learning\" OR \"deep learning\" OR \"art...   \n",
       "\n",
       "                                                 Title               URL  \\\n",
       "0    Evaluating risk prediction models for adults w...  /pubmed/31940350   \n",
       "1    Automated Cardiovascular Pathology Assessment ...  /pubmed/31939003   \n",
       "2    Physiological Assessment of Coronary Lesions i...  /pubmed/31938934   \n",
       "3    Of Machines and Men: Intelligent Diagnosis and...  /pubmed/31938923   \n",
       "4    Cytosine and adenine base editing of the brain...  /pubmed/31937940   \n",
       "..                                                 ...               ...   \n",
       "876  Lung Innate Lymphoid Cell Composition Is Alter...  /pubmed/31394048   \n",
       "974  Curcumin: a therapeutic strategy in cancers by...  /pubmed/31331376   \n",
       "976  Extra Virgin Olive Oil Contains a Phenolic Inh...  /pubmed/31331073   \n",
       "977  Effect of Vasicinone against Paraquat-Induced ...  /pubmed/31331066   \n",
       "991  Practical guide for the use of PCSK9 inhibitor...  /pubmed/31324407   \n",
       "\n",
       "                                              Abstract  \\\n",
       "0    BACKGROUND: The ability to predict risk allows...   \n",
       "1    Cardiac magnetic resonance imaging provides hi...   \n",
       "2    PURPOSE OF REVIEW: Physiological assessment of...   \n",
       "3    Artificial Intelligence (AI), although well es...   \n",
       "4    The success of base editors for the study and ...   \n",
       "..                                                 ...   \n",
       "876  Comment in\\n    Am J Respir Crit Care Med. 202...   \n",
       "974  Numerous studies have presented that curcumin ...   \n",
       "976  The lysine-specific histone demethylase 1A (LS...   \n",
       "977  Vasicinone is a quinazoline alkaloid isolated ...   \n",
       "991  Reducing low-density lipoprotein cholesterol (...   \n",
       "\n",
       "                                           Description  \\\n",
       "0           Di Tanna GL, Wirtz H, Burrows KL, Globe G.   \n",
       "1                                   Lindsey T, Lee JJ.   \n",
       "2                              Chowdhury M, Osborn EA.   \n",
       "3                               Cockcroft J, Avolio A.   \n",
       "4    Levy JM, Yeh WH, Pendse N, Davis JR, Hennessey...   \n",
       "..                                                 ...   \n",
       "876  Monticelli LA, Diamond JM, Saenz SA, Tait Wojn...   \n",
       "974               Vallée A, Lecarpentier Y, Vallée JN.   \n",
       "976  Cuyàs E, Gumuzio J, Lozano-Sánchez J, Carreras...   \n",
       "977  Ju DT, Sivalingam K, Kuo WW, Ho TJ, Chang RL, ...   \n",
       "991  Fontes-Carvalho R, Marques Silva P, Rodrigues ...   \n",
       "\n",
       "                                               Details  \\\n",
       "0    PloS one. doi: 10.1371/journal.pone.0224135. J...   \n",
       "1    Journal of digital imaging. doi: 10.1007/s1027...   \n",
       "2    Current treatment options in cardiovascular me...   \n",
       "3    Current hypertension reports. doi: 10.1007/s11...   \n",
       "4    Nature biomedical engineering. doi: 10.1038/s4...   \n",
       "..                                                 ...   \n",
       "876  American journal of respiratory and critical c...   \n",
       "974  Journal of experimental &amp; clinical cancer ...   \n",
       "976  Nutrients. pii: E1656. doi: 10.3390/nu11071656...   \n",
       "977  Nutrients. pii: E1655. doi: 10.3390/nu11071655...   \n",
       "991  Revista portuguesa de cardiologia : orgao ofic...   \n",
       "\n",
       "                                          ShortDetails Resource  \\\n",
       "0                                       PloS one. 2020   PubMed   \n",
       "1                     Journal of digital imaging. 2020   PubMed   \n",
       "2    Current treatment options in cardiovascular me...   PubMed   \n",
       "3                   Current hypertension reports. 2020   PubMed   \n",
       "4                  Nature biomedical engineering. 2020   PubMed   \n",
       "..                                                 ...      ...   \n",
       "876  American journal of respiratory and critical c...   PubMed   \n",
       "974  Journal of experimental &amp; clinical cancer ...   PubMed   \n",
       "976                                    Nutrients. 2019   PubMed   \n",
       "977                                    Nutrients. 2019   PubMed   \n",
       "991  Revista portuguesa de cardiologia : orgao ofic...   PubMed   \n",
       "\n",
       "                        Type    Identifiers      Db  EntrezUID  \\\n",
       "0            Journal Article  PMID:31940350  pubmed   31940350   \n",
       "1            Journal Article  PMID:31939003  pubmed   31939003   \n",
       "2    Journal Article, Review  PMID:31938934  pubmed   31938934   \n",
       "3    Journal Article, Review  PMID:31938923  pubmed   31938923   \n",
       "4            Journal Article  PMID:31937940  pubmed   31937940   \n",
       "..                       ...            ...     ...        ...   \n",
       "876          Journal Article  PMID:31394048  pubmed   31394048   \n",
       "974  Journal Article, Review  PMID:31331376  pubmed   31331376   \n",
       "976          Journal Article  PMID:31331073  pubmed   31331073   \n",
       "977          Journal Article  PMID:31331066  pubmed   31331066   \n",
       "991  Journal Article, Review  PMID:31324407  pubmed   31324407   \n",
       "\n",
       "                                            Properties  \n",
       "0    create date: 2020/01/15 | first author: Di Tan...  \n",
       "1    create date: 2020/01/14 | first author: Lindsey T  \n",
       "2    create date: 2020/01/15 | first author: Chowdh...  \n",
       "3    create date: 2020/01/14 | first author: Cockcr...  \n",
       "4      create date: 2020/01/14 | first author: Levy JM  \n",
       "..                                                 ...  \n",
       "876  create date: 2020/01/01 | first author: Montic...  \n",
       "974   create date: 2019/07/22 | first author: Vallée A  \n",
       "976    create date: 2019/07/19 | first author: Cuyàs E  \n",
       "977      create date: 2019/07/19 | first author: Ju DT  \n",
       "991  create date: 2019/06/01 | first author: Fontes...  \n",
       "\n",
       "[88 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#creating a pandas dataframe out of the csv file\n",
    "traindf = pd.read_csv('../Data/08.Pubmed_PDFs_011620.csv')\n",
    "testdf = pd.read_csv('../Data/04.Pubmed_PDFs_011320.csv')\n",
    "\n",
    "out = [x[:13] for x in testdf[\"Identifiers\"]]\n",
    "#print(out)\n",
    "\n",
    "subdf = traindf[~traindf[\"Identifiers\"].isin(out)]\n",
    "print(subdf.shape)\n",
    "subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words=text.ENGLISH_STOP_WORDS)\n",
    "documentlist = subdf['Abstract'].values\n",
    "X = vectorizer.fit_transform(documentlist)\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study',\n",
       " 'disease',\n",
       " 'heart',\n",
       " 'associated',\n",
       " 'treatment',\n",
       " 'use',\n",
       " 'cell',\n",
       " 'diseases',\n",
       " 'therapeutic',\n",
       " 'ability',\n",
       " 'type',\n",
       " 'targeted',\n",
       " 'limited',\n",
       " 'tissues',\n",
       " 'efficient',\n",
       " 'causes',\n",
       " 'increasing',\n",
       " 'genetic',\n",
       " 'introduction',\n",
       " 'mutations',\n",
       " 'multiple',\n",
       " 'application',\n",
       " '20',\n",
       " 'report',\n",
       " 'muscle',\n",
       " 'facilitate',\n",
       " 'liver',\n",
       " 'neurodegenerative',\n",
       " 'point',\n",
       " 'deliver',\n",
       " 'enable',\n",
       " 'depends',\n",
       " 'types',\n",
       " 'viruses',\n",
       " 'capacity',\n",
       " 'length',\n",
       " 'adenine',\n",
       " '59',\n",
       " 'cortical',\n",
       " 'skeletal',\n",
       " 'mutation',\n",
       " 'slowing',\n",
       " 'neurodegeneration',\n",
       " 'vectors',\n",
       " 'tissue',\n",
       " 'success',\n",
       " 'adeno',\n",
       " 'aav',\n",
       " 'packaging',\n",
       " 'precludes',\n",
       " 'split',\n",
       " 'cytosine',\n",
       " 'reconstituted',\n",
       " 'trans',\n",
       " 'splicing',\n",
       " 'inteins',\n",
       " 'therapeutically',\n",
       " 'efficiencies',\n",
       " 'dosages',\n",
       " 'unsorted',\n",
       " 'retina',\n",
       " 'corrects',\n",
       " 'niemann',\n",
       " 'pick',\n",
       " 'ataxia',\n",
       " 'lifespan',\n",
       " 'relevant',\n",
       " 'vivo',\n",
       " 'brain',\n",
       " 'mouse',\n",
       " '38',\n",
       " 'dual',\n",
       " 'optimized',\n",
       " 'editing',\n",
       " 'delivery',\n",
       " 'editors',\n",
       " 'aavs',\n",
       " 'base']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc =  4\n",
    "wordlist = X[doc,:].nonzero()[1]\n",
    "vallist = [X[doc, x] for x in wordlist]\n",
    "topwords = sorted(range(len(vallist)), key=lambda i: vallist[i])[-200:]\n",
    "[words[i] for i in wordlist[topwords]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04034532205181334,\n",
       " 0.0459783742357598,\n",
       " 0.0466999883519598,\n",
       " 0.049839998484588886,\n",
       " 0.05069779596505863,\n",
       " 0.056661056409636486,\n",
       " 0.05782689838935194,\n",
       " 0.06173287179469072,\n",
       " 0.06645229352398956,\n",
       " 0.07241555396856741,\n",
       " 0.07241555396856741,\n",
       " 0.0748102863331974,\n",
       " 0.07748736935362165,\n",
       " 0.07748736935362165,\n",
       " 0.08052239576380518,\n",
       " 0.08052239576380518,\n",
       " 0.08052239576380518,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08402607662287498,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.08817005152749834,\n",
       " 0.09324186691255257,\n",
       " 0.09324186691255257,\n",
       " 0.09324186691255257,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.09978057418180593,\n",
       " 0.10452283782704917,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.10899636447148349,\n",
       " 0.12261019103056649,\n",
       " 0.1266648253819354,\n",
       " 0.13633626735941884,\n",
       " 0.1422685147275347,\n",
       " 0.14928487415360892,\n",
       " 0.18454688719617648,\n",
       " 0.18454688719617648,\n",
       " 0.18454688719617648,\n",
       " 0.20940073914829785,\n",
       " 0.22874110990000346,\n",
       " 0.22874110990000346,\n",
       " 0.2844192457693743]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vallist[i] for i in topwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technical aspects involved', 'rest without hyperemia', 'residual ischemia post', 'optical coherence tomography', 'interventional cardiology toolbox', 'improve patient care', 'hyperemic pressure ratios', 'exciting technological future', 'enable detailed pre', 'artificial intelligence algorithms', 'alternative ffr approaches', 'invasive coronary ct', 'coronary artery disease', 'acute coronary syndromes', 'refine clinical practice', 'coronary physiological assessment', 'assess coronary physiology', 'ffr ), non', 'physiological assessment', 'coronary physiology', 'current practice', 'clinical scenarios', 'ffroct ),', 'ffrangio ),', 'well established', 'serial lesions', 'robust tools', 'remains underutilized', 'related arteries', 'recent findings', 'left main', 'latest developments', 'indispensable tool', 'including non', 'essential component', 'especially helpful', 'despite long', 'catheterization laboratory', 'also emerging', 'additional advances', 'stable cad', 'multivessel cad', 'review outlines', 'physiology', 'non', 'cad', 'review', 'virtual', 'today', 'realized', 'purpose', 'procedure', 'pci', 'nhpr', 'intervention', 'infarct', 'indications', 'however', 'focusing', 'field', 'benefits', 'addition', 'abound']\n",
      "[(9.0, 'technical aspects involved'), (9.0, 'rest without hyperemia'), (9.0, 'residual ischemia post'), (9.0, 'optical coherence tomography'), (9.0, 'interventional cardiology toolbox'), (9.0, 'improve patient care'), (9.0, 'hyperemic pressure ratios'), (9.0, 'exciting technological future'), (9.0, 'enable detailed pre'), (9.0, 'artificial intelligence algorithms'), (9.0, 'alternative ffr approaches'), (8.833333333333334, 'invasive coronary ct'), (8.833333333333334, 'coronary artery disease'), (8.833333333333334, 'acute coronary syndromes'), (8.0, 'refine clinical practice'), (7.833333333333334, 'coronary physiological assessment'), (7.833333333333334, 'assess coronary physiology'), (7.333333333333334, 'ffr ), non'), (5.0, 'physiological assessment'), (4.833333333333334, 'coronary physiology'), (4.5, 'current practice'), (4.5, 'clinical scenarios'), (4.333333333333334, 'ffroct ),'), (4.333333333333334, 'ffrangio ),'), (4.0, 'well established'), (4.0, 'serial lesions'), (4.0, 'robust tools'), (4.0, 'remains underutilized'), (4.0, 'related arteries'), (4.0, 'recent findings'), (4.0, 'left main'), (4.0, 'latest developments'), (4.0, 'indispensable tool'), (4.0, 'including non'), (4.0, 'essential component'), (4.0, 'especially helpful'), (4.0, 'despite long'), (4.0, 'catheterization laboratory'), (4.0, 'also emerging'), (4.0, 'additional advances'), (3.666666666666667, 'stable cad'), (3.666666666666667, 'multivessel cad'), (3.5, 'review outlines'), (2.0, 'physiology'), (2.0, 'non'), (1.6666666666666667, 'cad'), (1.5, 'review'), (1.0, 'virtual'), (1.0, 'today'), (1.0, 'realized'), (1.0, 'purpose'), (1.0, 'procedure'), (1.0, 'pci'), (1.0, 'nhpr'), (1.0, 'intervention'), (1.0, 'infarct'), (1.0, 'indications'), (1.0, 'however'), (1.0, 'focusing'), (1.0, 'field'), (1.0, 'benefits'), (1.0, 'addition'), (1.0, 'abound')]\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake #https://pypi.org/project/rake-nltk/\n",
    "from nltk.corpus import stopwords \n",
    "r = Rake(stopwords = stopwords.words(\"english\"), max_length = 3) # Uses stopwords for english from NLTK, and all puntuation characters.Please note that \"hello\" is not included in the list of stopwords.\n",
    "\n",
    "a=r.extract_keywords_from_text(subdf['Abstract'][2])\n",
    "b=r.get_ranked_phrases()\n",
    "c=r.get_ranked_phrases_with_scores()\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 6148: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-a3e117681e46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mglove_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../Data/glove.6B.300d.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mnum_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Output: Gensim Model text format.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-a3e117681e46>\u001b[0m in \u001b[0;36mget_lines\u001b[1;34m(glove_file_name)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnum_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mnum_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-a3e117681e46>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnum_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mnum_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 6148: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import smart_open\n",
    "from sys import platform\n",
    "\n",
    "import gensim\n",
    "\n",
    "\n",
    "def prepend_line(infile, outfile, line):\n",
    "\t\"\"\" \n",
    "\tFunction use to prepend lines using bash utilities in Linux. \n",
    "\t(source: http://stackoverflow.com/a/10850588/610569)\n",
    "\t\"\"\"\n",
    "\twith open(infile, 'r') as old:\n",
    "\t\twith open(outfile, 'w') as new:\n",
    "\t\t\tnew.write(str(line) + \"\\n\")\n",
    "\t\t\tshutil.copyfileobj(old, new)\n",
    "\n",
    "def prepend_slow(infile, outfile, line):\n",
    "\t\"\"\"\n",
    "\tSlower way to prepend the line by re-creating the inputfile.\n",
    "\t\"\"\"\n",
    "\twith open(infile, 'r') as fin:\n",
    "\t\twith open(outfile, 'w') as fout:\n",
    "\t\t\tfout.write(line + \"\\n\")\n",
    "\t\t\tfor line in fin:\n",
    "\t\t\t\tfout.write(line)\n",
    "\n",
    "def get_lines(glove_file_name):\n",
    "    \"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\n",
    "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
    "        num_lines = sum(1 for line in f)\n",
    "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
    "        num_dims = len(f.readline().split()) - 1\n",
    "    return num_lines, num_dims\n",
    "\t\n",
    "# Input: GloVe Model File\n",
    "# More models can be downloaded from http://nlp.stanford.edu/projects/glove/\n",
    "glove_file=\"../Data/glove.6B.300d.txt\"\n",
    "\n",
    "num_lines, dims = get_lines(glove_file)\n",
    "\n",
    "# Output: Gensim Model text format.\n",
    "gensim_file='glove_model2.txt'\n",
    "gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
    "\n",
    "# Prepends the line.\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "\tprepend_line(glove_file, gensim_file, gensim_first_line)\n",
    "else:\n",
    "\tprepend_slow(glove_file, gensim_file, gensim_first_line)\n",
    "\n",
    "# Demo: Loads the newly created glove_model.txt into gensim API.\n",
    "model=gensim.models.Word2Vec.load_word2vec_format(gensim_file,binary=False) #GloVe Model\n",
    "\n",
    "print (model.most_similar(positive=['australia'], topn=10))\n",
    "print (model.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../Data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coughs', 0.7185554504394531),\n",
       " ('coughing', 0.6782324314117432),\n",
       " ('Cough', 0.6303825974464417),\n",
       " ('stuffy_nose', 0.5673868656158447),\n",
       " ('sore_throat', 0.5565829277038574),\n",
       " ('hacking_cough', 0.5461398959159851),\n",
       " ('nasal_congestion_sore_throat', 0.5426505208015442),\n",
       " ('sneezing_watery_eyes', 0.5395500063896179),\n",
       " ('Cough_cough', 0.5355319976806641),\n",
       " ('cough_sore_throat', 0.5340639352798462)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('cough', 'nausea')\n",
    "model.most_similar(positive=['cough'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
